{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#x1F4D1; &nbsp;  $\\mathfrak {\\color{#348ABD} {P5: \\ Build \\ a \\ Digit \\ Recognition \\ Program}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Code \\ Library \\ and \\ Links}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-dimensional image processing https://docs.scipy.org/doc/scipy/reference/ndimage.html\n",
    "\n",
    "Keras: Deep Learning library for Theano and TensorFlow https://keras.io/\n",
    " \n",
    "Deep MNIST for Experts https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "Tensorflow Deep MNIST Advanced Tutorial http://docs.seldon.io/tensorflow-deep-mnist-example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>code_show = true; \n",
       "function code_display() {\n",
       "    if (code_show) {\n",
       "        $('div.input').each(function(id) {\n",
       "            if (id == 0 || $(this).html().indexOf('hide_code') > -1) {$(this).hide();}\n",
       "        });\n",
       "        $('div.output_prompt').css('opacity', 0);\n",
       "    } else {\n",
       "        $('div.input').each(function(id) {$(this).show();});\n",
       "        $('div.output_prompt').css('opacity', 1);\n",
       "    }\n",
       "    code_show = !code_show;\n",
       "} \n",
       "$(document).ready(code_display);</script>\n",
       "<form action=\"javascript: code_display()\"><input style=\"color: #348ABD; background: ghostwhite; opacity: 0.9; \" type=\"submit\" value=\"Click to display or hide code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "hide_code = ''\n",
    "HTML('''<script>code_show = true; \n",
    "function code_display() {\n",
    "    if (code_show) {\n",
    "        $('div.input').each(function(id) {\n",
    "            if (id == 0 || $(this).html().indexOf('hide_code') > -1) {$(this).hide();}\n",
    "        });\n",
    "        $('div.output_prompt').css('opacity', 0);\n",
    "    } else {\n",
    "        $('div.input').each(function(id) {$(this).show();});\n",
    "        $('div.output_prompt').css('opacity', 1);\n",
    "    }\n",
    "    code_show = !code_show;\n",
    "} \n",
    "$(document).ready(code_display);</script>\n",
    "<form action=\"javascript: code_display()\"><input style=\"color: #348ABD; background: ghostwhite; opacity: 0.9; \" \\\n",
    "type=\"submit\" value=\"Click to display or hide code\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from IPython.display import display, Image, IFrame\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import offsetbox\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import manifold, decomposition, ensemble\n",
    "from sklearn import discriminant_analysis, random_projection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.layers import Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Experimental \\ Datasets}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #1. Scikit-learn. Digits.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second dataset\n",
      "Shape of the features - (1797, 64); shape of the target - (1797,)\n"
     ]
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "X, y = digits.data, digits.target\n",
    "print('The second dataset')\n",
    "print(\"Shape of the features - {}; shape of the target - {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAFoCAYAAAD5IVjuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAN0GIrhBAN+P/dmBwxj/BH/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121947a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "img = np.zeros((100, 100))\n",
    "for i in range(10):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(10):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * 10 + j].reshape((8, 8))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Examples of the 64-dimensional digits');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #2. MNIST \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/contrib/keras/datasets/mnist/load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "mnist_data = mnist.input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_images = mnist_data.train.images\n",
    "train_labels = mnist_data.train.labels\n",
    "test_images = mnist_data.test.images\n",
    "test_labels = mnist_data.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first dataset\n",
      "Shape of the train features - (55000, 784), shape of the train target - (55000, 10)\n",
      "Shape of the test features - (10000, 784), shape of the test target - (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "print('The first dataset')\n",
    "print(\"Shape of the train features - {}, shape of the train target - {}\".\\\n",
    "      format(train_images.shape, train_labels.shape))\n",
    "print(\"Shape of the test features - {}, shape of the test target - {}\".\\\n",
    "      format(test_images.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "train_images28 = np.array([np.reshape(x, (28,28)) for x in train_images])\n",
    "test_images28 = np.array([np.reshape(x, (28,28)) for x in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAACOCAYAAADtoZ5aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ee17c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(train_images28[y_train == 2], cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Example of the 784-dimensional digits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = train_images28[y_train == i][0]\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #3. Stanford.edu. Housenumbers\n",
    "\n",
    "http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "last_percent_reported = None\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    \"\"\"\n",
    "    A hook to report the progress of a download. This is mostly intended for users with\n",
    "    slow internet connections. Reports every 1% change in download progress.\n",
    "    \"\"\"\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        last_percent_reported = percent\n",
    "               \n",
    "def maybe_download(filename, force=False):\n",
    "    \"\"\"\n",
    "    Download a file if not present, and make sure it's the right size.\n",
    "    \"\"\"\n",
    "    if force or not os.path.exists(filename):\n",
    "        print('Attempting to download:', filename) \n",
    "        filename, _ = urlretrieve(url + filename, filename, reporthook=download_progress_hook)\n",
    "        print('\\nDownload Complete!')\n",
    "    else:\n",
    "        print(filename, 'is already downloaded. Skipped.')\n",
    "    return filename\n",
    "\n",
    "def maybe_extract(file_, force=False):\n",
    "    filename = os.path.splitext(os.path.splitext(file_)[0])[0]  # remove .tar.gz\n",
    "    \n",
    "    if os.path.isdir(filename) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s is already presented - Skipping extraction of %s.' % (filename, file_))\n",
    "    else:\n",
    "        print('Extracting %s file data. Please wait...' % file_)\n",
    "        tar = tarfile.open(file_)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        print('File %s is successfully extracted into %s directory.' % (file_, filename))        \n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tar.gz is already downloaded. Skipped.\n",
      "Attempting to download: test.tar.gz\n",
      "....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
      "Download Complete!\n",
      "Attempting to download: extra.tar.gz\n",
      "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%.."
     ]
    }
   ],
   "source": [
    "train_filename = maybe_download('train.tar.gz')\n",
    "test_filename = maybe_download('test.tar.gz')\n",
    "extra_filename = maybe_download('extra.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #4. Newly-Captured Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Step \\ 1:\\ Design \\ and \\ Test \\ a \\ Model \\ Architecture}}$\n",
    "In this project we will design and implement a deep learning model that learns to recognize sequences of digits. Also we will train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, we can for example limit ourself to sequences up to five digits, and use five classifiers on top of the deep network. We would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- The model can be derived from a deep neural net or a convolutional network.\n",
    "- We could experiment sharing or not the weights between the softmax classifiers.\n",
    "- We can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "We can use ** Keras ** to implement your model. Read more at [keras.io](https://keras.io/).\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0)). You are not expected to model your architecture precisely using this model nor get the same performance levels, but this is more to show an exampe of an approach used to solve this particular problem. We encourage you to try out different architectures for yourself and see what works best for you. Here is a useful [forum post](https://discussions.udacity.com/t/goodfellow-et-al-2013-architecture/202363) discussing the architecture as described in the paper and here is [another one](https://discussions.udacity.com/t/what-loss-function-to-use-for-multi-digit-svhn-training/176897) discussing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Models N1 and N2 are the classic examples, models N3 and N4 are designed for this project.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 # https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_code\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    def __init__(self, n_output, n_features, n_hidden=30,\n",
    "                 l1=0.0, l2=0.0, epochs=500, eta=0.001, \n",
    "                 alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_output = n_output\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.w1, self.w2 = self._initialize_weights()\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "\n",
    "    def _encode_labels(self, y, k):\n",
    "        onehot = np.zeros((k, y.shape[0]))\n",
    "        for idx, val in enumerate(y):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        w1 = np.random.uniform(-1.0, 1.0, size=self.n_hidden*(self.n_features + 1))\n",
    "        w1 = w1.reshape(self.n_hidden, self.n_features + 1)\n",
    "        \n",
    "        w2 = np.random.uniform(-1.0, 1.0, size=self.n_output*(self.n_hidden + 1))\n",
    "        w2 = w2.reshape(self.n_output, self.n_hidden + 1)\n",
    "        \n",
    "        return w1, w2\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        # expit is equivalent to 1.0/(1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "\n",
    "    def _sigmoid_gradient(self, z):\n",
    "        sg = self._sigmoid(z)\n",
    "        return sg * (1 - sg)\n",
    "\n",
    "    def _add_bias_unit(self, X, how='column'):\n",
    "        if how == 'column':\n",
    "            X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "            X_new[:, 1:] = X\n",
    "        elif how == 'row':\n",
    "            X_new = np.ones((X.shape[0]+1, X.shape[1]))\n",
    "            X_new[1:, :] = X\n",
    "        else:\n",
    "            raise AttributeError('`how` must be `column` or `row`')\n",
    "        return X_new\n",
    "\n",
    "    def _feedforward(self, X, w1, w2):\n",
    "        a1 = self._add_bias_unit(X, how='column')\n",
    "        z2 = w1.dot(a1.T)\n",
    "        a2 = self._sigmoid(z2)\n",
    "        a2 = self._add_bias_unit(a2, how='row')\n",
    "        z3 = w2.dot(a2)\n",
    "        a3 = self._sigmoid(z3)\n",
    "        return a1, z2, a2, z3, a3\n",
    "\n",
    "    def _L2_reg(self, lambda_, w1, w2):\n",
    "        return (lambda_/2.0) * (np.sum(w1[:, 1:] ** 2) + np.sum(w2[:, 1:] ** 2))\n",
    "\n",
    "    def _L1_reg(self, lambda_, w1, w2):\n",
    "        return (lambda_/2.0) * (np.abs(w1[:, 1:]).sum() + np.abs(w2[:, 1:]).sum())\n",
    "\n",
    "    def _get_cost(self, y_enc, output, w1, w2):\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1 - y_enc) * np.log(1 - output)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        L1_term = self._L1_reg(self.l1, w1, w2)\n",
    "        L2_term = self._L2_reg(self.l2, w1, w2)\n",
    "        cost = cost + L1_term + L2_term\n",
    "        return cost\n",
    "\n",
    "    def _get_gradient(self, a1, a2, a3, z2, y_enc, w1, w2):\n",
    "        # backpropagation\n",
    "        sigma3 = a3 - y_enc\n",
    "        z2 = self._add_bias_unit(z2, how='row')\n",
    "        sigma2 = w2.T.dot(sigma3) * self._sigmoid_gradient(z2)\n",
    "        sigma2 = sigma2[1:, :]\n",
    "        grad1 = sigma2.dot(a1)\n",
    "        grad2 = sigma3.dot(a2.T)\n",
    "\n",
    "        # regularize\n",
    "        grad1[:, 1:] += (w1[:, 1:] * (self.l1 + self.l2))\n",
    "        grad2[:, 1:] += (w2[:, 1:] * (self.l1 + self.l2))\n",
    "\n",
    "        return grad1, grad2\n",
    "\n",
    "    def predict(self, X):\n",
    "        a1, z2, a2, z3, a3 = self._feedforward(X, self.w1, self.w2)\n",
    "        y_pred = np.argmax(z3, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        self.cost_ = []\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        y_enc = self._encode_labels(y, self.n_output)\n",
    "\n",
    "        delta_w1_prev = np.zeros(self.w1.shape)\n",
    "        delta_w2_prev = np.zeros(self.w2.shape)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx = np.random.permutation(y_data.shape[0])\n",
    "                X_data, y_enc = X_data[idx], y_enc[:,idx]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                a1, z2, a2, z3, a3 = self._feedforward(X_data[idx], self.w1, self.w2)\n",
    "                cost = self._get_cost(y_enc=y_enc[:, idx], output=a3, w1=self.w1, w2=self.w2)\n",
    "                \n",
    "                self.cost_.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(a1=a1, a2=a2, a3=a3, z2=z2,\n",
    "                                                  y_enc=y_enc[:, idx], w1=self.w1, w2=self.w2)\n",
    "\n",
    "                # update weights\n",
    "                delta_w1, delta_w2 = self.eta * grad1, self.eta * grad2\n",
    "                self.w1 -= (delta_w1 + (self.alpha * delta_w1_prev))\n",
    "                self.w2 -= (delta_w2 + (self.alpha * delta_w2_prev))\n",
    "                delta_w1_prev, delta_w2_prev = delta_w1, delta_w2\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_output=10, n_features=train_images.shape[1], n_hidden=50, \n",
    "                  l2=0.1, l1=0.0, epochs=1000, \n",
    "                  eta=0.001, alpha=0.001, decrease_const=0.00001,\n",
    "                  shuffle=True, minibatches=50, random_state=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #2 http://cs231n.github.io/neural-networks-case-study/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2 # dimensionality\n",
    "K = 10 # number of classes\n",
    "h = 500 # size of hidden layer\n",
    "\n",
    "W = 0.001 * np.random.randn(D,h)\n",
    "b = np.zeros((1,h))\n",
    "W2 = 0.001 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# some hyperparameters\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "for i in range(1000):\n",
    "  \n",
    "    # evaluate class scores, [N x K]\n",
    "    hidden_layer = np.maximum(0, np.dot(X, W) + b) # ReLU activation\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "  \n",
    "    # compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "  \n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = -np.log(probs[range(num_examples),y])\n",
    "    data_loss = np.sum(corect_logprobs)/num_examples\n",
    "    reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n",
    "    loss = data_loss + reg_loss\n",
    "    if i % 1000 == 0:\n",
    "        print (\"iteration %d: loss %f\" % (i, loss))\n",
    "  \n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(num_examples),y] -= 1\n",
    "    dscores /= num_examples\n",
    "  \n",
    "    # backpropate the gradient to the parameters\n",
    "    # first backprop into parameters W2 and b2\n",
    "    dW2 = np.dot(hidden_layer.T, dscores)\n",
    "    db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    # next backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    # backprop the ReLU non-linearity\n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    # finally into W,b\n",
    "    dW = np.dot(X.T, dhidden)\n",
    "    db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "  \n",
    "    # add regularization gradient contribution\n",
    "    dW2 += reg * W2\n",
    "    dW += reg * W\n",
    "  \n",
    "    # perform a parameter update\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate training set accuracy\n",
    "scores = np.dot(X, W) + b\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print ('training accuracy: %.2f' % (np.mean(predicted_class == y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "# def model3():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code\n",
    "\n",
    "# def model4():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_\n",
    "### Answer 1\n",
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_\n",
    "### Answer 2\n",
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed.\n",
    "### Answer 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Step \\ 2:\\ Train \\ a \\ Model \\ on \\ a \\ Realistic \\ Dataset}}$\n",
    "Once we have settled on a good architecture, we can train the model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code\n",
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_\n",
    "### Answer 4\n",
    "\n",
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_\n",
    "### Answer 5\n",
    "\n",
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_\n",
    "### Answer 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Step \\ 3: \\ Test \\ a \\ Model \\ on \\ Newly-Captured \\ Images}}$\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code\n",
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_\n",
    "\n",
    "### Answer 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_\n",
    "\n",
    "### Answer 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n",
    "\n",
    "### Answer 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Step \\ 4: \\ Explore \\ an \\ Improvement \\ for \\ a \\ Model}}$\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hide_code\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_\n",
    "### Answer 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image.\n",
    "\n",
    "### Answer 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "## $\\mathfrak {\\color{#348ABD} {Optional \\ Step \\ 5: \\ Build \\ an \\ Application \\ or \\ Program \\ for \\ a \\ Model}}$\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
